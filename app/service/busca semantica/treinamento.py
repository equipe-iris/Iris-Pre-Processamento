import pandas as pd
import random
import os
import logging
import argparse
from sentence_transformers import SentenceTransformer, InputExample, losses, evaluation, models
from torch.utils.data import DataLoader
import faiss
import numpy as np
import shutil

# ConfiguraÃ§Ã£o de logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

# ParÃ¢metros globais
MODELO_SALVO = "modelo_semantico_treinado"
INDEX_SALVO = "indice_faiss.index"
CSV_CAMINHO = "dataset_so_interacao.csv"
CHECKPOINT_DIR = "checkpoints2"
METRICAS_CSV = "metricas_treinamento.csv"
SEED = 42
BEST_CHECKPOINT_DIR = os.path.join(CHECKPOINT_DIR, "best")

def set_seed(seed):
    """Garante reprodutibilidade."""
    random.seed(seed)
    np.random.seed(seed)
    try:
        import torch
        torch.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
    except ImportError:
        pass

def gerar_pares_artificiais(df, coluna_texto="DescriÃ§Ã£o"):
    """
    Gera pares positivos (texto, texto) e negativos (texto, outro_texto).
    """
    textos = df[coluna_texto].tolist()
    exemplos = []
    for i, original in enumerate(textos):
        exemplos.append(InputExample(texts=[original, original], label=1.0))
        # Par negativo: sorteia outro texto diferente
        negativo_idx = random.choice([j for j in range(len(textos)) if j != i])
        negativo = textos[negativo_idx]
        exemplos.append(InputExample(texts=[original, negativo], label=0.0))
    return exemplos

def carregar_dados_csv(csv_path=CSV_CAMINHO):
    """
    Carrega e limpa o CSV, retorna DataFrame apenas com a coluna 'DescriÃ§Ã£o'.
    """
    df = pd.read_csv(csv_path, sep=";", encoding="utf-8", engine="python", on_bad_lines="warn", quoting=3)
    df = df.sample(frac=0.5, random_state=SEED) 
    if "DescriÃ§Ã£o" not in df.columns:
        raise ValueError("Coluna 'DescriÃ§Ã£o' nÃ£o encontrada no CSV.")
    df["DescriÃ§Ã£o"] = df["DescriÃ§Ã£o"].fillna("").str.strip()
    df = df[df["DescriÃ§Ã£o"] != ""]
    df = df[["DescriÃ§Ã£o"]].drop_duplicates().reset_index(drop=True)
    print(df.head(10))  # Debug: veja as primeiras linhas
    return df

def split_train_val(df, val_frac=0.1):
    """
    Divide o DataFrame em treino e validaÃ§Ã£o.
    """
    df = df.sample(frac=1, random_state=SEED).reset_index(drop=True)
    val_size = int(len(df) * val_frac)
    return df.iloc[val_size:], df.iloc[:val_size]

def treinar_modelo(df_train, df_val, epochs, patience=3):
    """
    Treina o modelo SentenceTransformer com early stopping e salva mÃ©tricas.
    """
    # Inicializa modelo
    if os.path.exists(CHECKPOINT_DIR) and os.path.exists(os.path.join(CHECKPOINT_DIR, "config.json")):
        logging.info("ğŸ” Carregando modelo salvo anteriormente...")
        model = SentenceTransformer(CHECKPOINT_DIR)
    else:
        logging.info("ğŸ§  Criando novo modelo do zero...")
        word_embedding_model = models.Transformer('sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2')
        pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())
        model = SentenceTransformer(modules=[word_embedding_model, pooling_model])
        os.makedirs(CHECKPOINT_DIR, exist_ok=True)

    exemplos_train = gerar_pares_artificiais(df_train)
    exemplos_val = gerar_pares_artificiais(df_val)
    dataloader = DataLoader(exemplos_train, shuffle=True, batch_size=4)
    loss = losses.CosineSimilarityLoss(model)
    evaluator = evaluation.EmbeddingSimilarityEvaluator.from_input_examples(exemplos_val, name='avaliacao')

    # Early stopping manual
    best_score = -np.inf
    best_epoch = 0
    patience_counter = 0
    metricas = []

    for epoch in range(1, epochs + 1):
        logging.info(f"ğŸš€ Iniciando epoch {epoch}/{epochs}")
        model.fit(
            train_objectives=[(dataloader, loss)],
            epochs=1,
            warmup_steps=5,
            show_progress_bar=True
        )
        score = evaluator(model)
        # Exemplo de extraÃ§Ã£o da mÃ©trica cosine_similarity
        cosine_score = score['cosine_similarity'] if 'cosine_similarity' in score else list(score.values())[0]
        logging.info(f"ğŸ“Š Epoch {epoch}: ValidaÃ§Ã£o (CosineSimilarity) = {cosine_score:.4f}")
        metricas.append({"epoch": epoch, "val_score": cosine_score})

        # Early stopping
        if cosine_score > best_score:
            best_score = cosine_score
            best_epoch = epoch
            patience_counter = 0
            # Limpa o diretÃ³rio antes de salvar para evitar erro safetensors
            if os.path.exists(BEST_CHECKPOINT_DIR):
                shutil.rmtree(BEST_CHECKPOINT_DIR)
            model.save(BEST_CHECKPOINT_DIR)
            logging.info(f"ğŸ’¾ Novo melhor modelo salvo (epoch {epoch})")
        else:
            patience_counter += 1
            if patience_counter >= patience:
                logging.info(f"â¹ï¸ Early stopping ativado em epoch {epoch}")
                break

    # Salva mÃ©tricas em CSV
    pd.DataFrame(metricas).to_csv(METRICAS_CSV, index=False)
    logging.info(f"ğŸ“ˆ MÃ©tricas salvas em {METRICAS_CSV}")

    # Carrega o melhor modelo salvo
    model = SentenceTransformer(BEST_CHECKPOINT_DIR)
    return model

def construir_indice_faiss(model, textos):
    """
    Gera embeddings e constrÃ³i Ã­ndice FAISS.
    """
    embeddings = model.encode(textos, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=True)
    dim = embeddings.shape[1]
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)
    faiss.write_index(index, INDEX_SALVO)
    logging.info(f"âœ… Ãndice FAISS salvo como {INDEX_SALVO}")
    return index

def modo_pesquisa_interativo(model, index, textos):
    """
    Interface de busca semÃ¢ntica interativa.
    SÃ³ busca na coluna 'DescriÃ§Ã£o' e evita duplicatas.
    """
    print("\nğŸ§  Modo de busca semÃ¢ntica. Digite 'sair' para encerrar.\n")
    while True:
        consulta = input("ğŸ” Digite sua pesquisa: ").strip()
        if consulta.lower() in ["sair", "exit", "quit"]:
            print("ğŸ‘‹ Encerrando pesquisa.")
            break
        embedding = model.encode([consulta], convert_to_numpy=True, normalize_embeddings=True)
        distances, indices = index.search(embedding, 5)
        resultados = []
        usados = set()
        print("\nğŸ” Resultados:")
        for i, idx in enumerate(indices[0]):
            texto = textos[idx]
            if texto not in usados:
                usados.add(texto)
                print(f"{len(resultados)+1}. {texto} (similaridade: {distances[0][i]:.4f})")
                resultados.append(texto)
            if len(resultados) >= 5:
                break
        if not resultados:
            print("Nenhum resultado encontrado.")
        print("-" * 40)

def main():
    set_seed(SEED)
    parser = argparse.ArgumentParser(description="Treinamento e busca semÃ¢ntica.")
    parser.add_argument("--epochs", type=int, default=10, help="NÃºmero mÃ¡ximo de epochs para treinamento")
    parser.add_argument("--val_frac", type=float, default=0.1, help="FraÃ§Ã£o de validaÃ§Ã£o")
    parser.add_argument("--patience", type=int, default=3, help="Paciencia para early stopping")
    args = parser.parse_args()

    df = carregar_dados_csv()
    logging.info(f"ğŸ“„ {len(df)} textos carregados.")

    df_train, df_val = split_train_val(df, val_frac=args.val_frac)
    logging.info(f"ğŸ”— {len(df_train)} exemplos de treino, {len(df_val)} de validaÃ§Ã£o.")

    model = treinar_modelo(df_train, df_val, args.epochs, patience=args.patience)
    index = construir_indice_faiss(model, df["DescriÃ§Ã£o"].tolist())
    modo_pesquisa_interativo(model, index, df["DescriÃ§Ã£o"].tolist())

if __name__ == "__main__":
    main()
